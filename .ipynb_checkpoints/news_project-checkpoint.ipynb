{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newsapi-python\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/44/1bcbf1a73fb9fd17047869f1569f4a0d0650b0bc234ba783e497e8984bf3/newsapi-python-0.2.3.tar.gz\n",
      "Collecting requests==2.17.1 (from newsapi-python)\n",
      "  Downloading https://files.pythonhosted.org/packages/50/41/f6fdaf24a80c726a72f76b15869a20734b7a527081129a380ddce99ffae0/requests-2.17.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting idna<2.6,>=2.5 (from requests==2.17.1->newsapi-python)\n",
      "  Downloading https://files.pythonhosted.org/packages/11/7d/9bbbd7bb35f34b0169542487d2a8859e44306bb2e6a4455d491800a5621f/idna-2.5-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/shubyog/anaconda2/envs/fastai-cpu/lib/python3.6/site-packages (from requests==2.17.1->newsapi-python)\n",
      "Collecting urllib3<1.22,>=1.21.1 (from requests==2.17.1->newsapi-python)\n",
      "  Downloading https://files.pythonhosted.org/packages/24/53/f397db567de0aa0e81b211d81c13c41a779f14893e42189cf5bdb97611b2/urllib3-1.21.1-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/shubyog/anaconda2/envs/fastai-cpu/lib/python3.6/site-packages (from requests==2.17.1->newsapi-python)\n",
      "Building wheels for collected packages: newsapi-python\n",
      "  Running setup.py bdist_wheel for newsapi-python ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/shubyog/Library/Caches/pip/wheels/a0/58/f4/627d98e817f4c1819fc524ec3b3187534f8078e36c0d4048a1\n",
      "Successfully built newsapi-python\n",
      "Installing collected packages: idna, urllib3, requests, newsapi-python\n",
      "  Found existing installation: idna 2.6\n",
      "    Uninstalling idna-2.6:\n",
      "      Successfully uninstalled idna-2.6\n",
      "  Found existing installation: urllib3 1.22\n",
      "    Uninstalling urllib3-1.22:\n",
      "      Successfully uninstalled urllib3-1.22\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "Successfully installed idna-2.5 newsapi-python-0.2.3 requests-2.17.1 urllib3-1.21.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with a small quiz on Australia Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import *\n",
    "\n",
    "\n",
    "newsapi = NewsApiClient(api_key='')\n",
    "from datetime import datetime, timedelta\n",
    "today=datetime.today().strftime('%Y-%m-%d')\n",
    "ldate=(datetime.today()-timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "all_articles = newsapi.get_everything(q='Australia Sports',\n",
    "                                      sources='The Australian',\n",
    "\n",
    "\n",
    "                                      from_param=ldate,\n",
    "                                      to=today,\n",
    "                                      language='en',\n",
    "                                      sort_by='publishedAt',\n",
    "                                      page=1,\n",
    "                                      page_size=100\n",
    "\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description=[]\n",
    "Source=[]\n",
    "Date=[]\n",
    "\n",
    "#no_pages=np.ceil(all_articles['totalResults']/len(all_articles['articles']))\n",
    "no_pages=(all_articles['totalResults']/len(all_articles['articles']))+ (all_articles['totalResults'] % len(all_articles['articles']) > 0)\n",
    "\n",
    "\n",
    "i=1\n",
    "while i<=no_pages:\n",
    "\n",
    "\n",
    "    all_articles = newsapi.get_everything(q='Australia Sports',\n",
    "                                          sources='The Australian',\n",
    "                                          \n",
    "\n",
    "\n",
    "                                      from_param=ldate,\n",
    "                                      to=today,\n",
    "                                      language='en',\n",
    "                                      sort_by='publishedAt',\n",
    "                                      page=i,\n",
    "                                      page_size=100\n",
    "\n",
    "                                     )\n",
    "    j=0\n",
    "    while j<=len(all_articles['articles'])-1:\n",
    "        Title.append(all_articles['articles'][j]['title'])\n",
    "        Description.append(all_articles['articles'][j]['description'])\n",
    "        Source.append(all_articles['articles'][j]['source']['name'])\n",
    "        Date.append(all_articles['articles'][j]['publishedAt'])\n",
    "\n",
    "\n",
    "\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Comcast Wins Bidding for Ownership of Sky'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ' '.join(Title[40:41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripNonAlphaNum(text):\n",
    "    import re\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check=(stripNonAlphaNum(' '.join(Title[40:41])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statement=str(\" \".join(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comcast Wins Bidding for Ownership of Sky'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement #This will our first statement for fill in the blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Comcast', 'ORG')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc=nlp(' '.join(Title[40:41]))\n",
    "#doc=nlp(' '.join(u))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(str(ent.text),str(ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy recognisex Comcast so lets replace it by blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a fill in the blank\n",
    "\n",
    "str1=nlp(' '.join(Title[40:41]))\n",
    "PERSON_1=[]\n",
    "ORG_1=[]\n",
    "LOCATION_1=[]\n",
    "\n",
    "for ent in str1.ents:\n",
    "    if str(ent.label_)=='PERSON':\n",
    "        try:\n",
    "            PERSON_1.append(str(ent.text))\n",
    "        except:\n",
    "            pass\n",
    "    if str(ent.label_)=='ORG':\n",
    "        try:\n",
    "            ORG_1.append(str(ent.text))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if str(ent.label_)=='GPE':\n",
    "        try:\n",
    "            LOCATION_1.append(str(ent.text))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "                \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "           \n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comcast']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'______________ Wins Bidding for Ownership of Sky'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace ORG in the statement by a blank\n",
    "\n",
    "statement.replace(''.join(ORG_1),'______________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What are the options lets run our entity selection through whole corpus?\n",
    "\n",
    "i=1\n",
    "j=0\n",
    "PERSON=[]\n",
    "ORG=[]\n",
    "LOCATION=[]\n",
    "\n",
    "while i <=all_articles['totalResults']:\n",
    "    str1 = nlp(' '.join(Title[j:i]))\n",
    "    for ent in str1.ents:\n",
    "        \n",
    "        if str(ent.label_)=='PERSON':\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                PERSON.append(str(ent.text))\n",
    "            except:\n",
    "                   pass\n",
    "        \n",
    "        if str(ent.label_)=='ORG':\n",
    "            \n",
    "            try:\n",
    "                ORG.append(str(ent.text))\n",
    "            except:\n",
    "                   pass\n",
    "        \n",
    "        if str(ent.label_)=='GPE':\n",
    "            \n",
    "            try:\n",
    "                LOCATION.append(str(ent.text))\n",
    "            except:\n",
    "                   pass\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "           \n",
    "          \n",
    "        \n",
    "    \n",
    "    \n",
    "    #print(json.dumps(comprehend.detect_entities(Text=str1,LanguageCode='en'), sort_keys=True, indent=4))\n",
    "    #print(i)\n",
    "    #print(str1)\n",
    "    i+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove the current answer from the other options\n",
    "while ''.join(ORG_1) in ORG:\n",
    "    PERSON.remove(''.join(ORG_1))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove all duplicates from the list\n",
    "\n",
    "Final_ORG=[]\n",
    "\n",
    "for i in ORG:\n",
    "    \n",
    "    if i not in Final_ORG:\n",
    "        Final_ORG.append(i)\n",
    "        \n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select 3 from all article which are not part of original sentence\n",
    "\n",
    "Answer_options=[]\n",
    "import random\n",
    "num_to_select =3                           \n",
    "Answer_options= random.sample(Final_ORG,num_to_select)\n",
    "Answer_options.append(''.join(ORG_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'______________ Wins Bidding for Ownership of Sky'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question\n",
    "statement.replace(''.join(ORG_1),'______________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Buffalo Bills', 'Qantas', 'Kohli - India', 'Comcast']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And the options are:\n",
    "Answer_options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
